from picamera2 import Picamera2
import cv2
import time
import os

DATA_DIR = "faces_data"
MODEL_FILE = "me_model.yml"
LABEL_ME = 1

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è ---
LBPH_THRESHOLD = 70
FRAME_SLEEP = 0.25
ME_STREAK_ON = 5
ME_STREAK_OFF = 5

# --- –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –∫–æ–Ω—Å–æ–ª—ñ ---
TEXT_COOLDOWN_SEC = 30

# --- AI (—ñ–Ω—ñ—Ü—ñ–∞—Ç–∏–≤–Ω–∏–π) ---
AI_ENABLED = True
AI_COOLDOWN_SEC = 180  # AI –ø–∏—Ç–∞—î –º–∞–∫—Å–∏–º—É–º —Ä–∞–∑ –Ω–∞ 3 —Ö–≤, –ø–æ–∫–∏ —Ç–∏ –≤ –∫–∞–¥—Ä—ñ

# –°–ø—Ä–æ–±–∞ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏ ai_chat.py
try:
    from ai_chat import ask_ai
    AI_AVAILABLE = True
except Exception:
    AI_AVAILABLE = False
    ask_ai = None


def train_model():
    if not os.path.isdir(DATA_DIR):
        raise RuntimeError("No faces_data folder. Run enroll_me.py first.")

    images = []
    labels = []

    for fn in sorted(os.listdir(DATA_DIR)):
        if fn.lower().endswith(".png"):
            path = os.path.join(DATA_DIR, fn)
            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                images.append(img)
                labels.append(LABEL_ME)

    if len(images) < 10:
        raise RuntimeError("Need at least 10 samples. Run enroll_me.py again.")

    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.train(images, labels)
    recognizer.save(MODEL_FILE)


def safe_ai_prompt() -> str:
    # –ó–∞–ø–∞—Å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç –±–µ–∑ API
    return "–ü—Ä–∏–≤—ñ—Ç! –Ø –±–∞—á—É —Ç–µ–±–µ. –©–æ —Ö–æ—á–µ—à –∑—Ä–æ–±–∏—Ç–∏ –∑–∞—Ä–∞–∑? –Ø–∫—ñ –ø–ª–∞–Ω–∏?"


def get_proactive_ai_message() -> str:
    """
    1 –∫–æ—Ä–æ—Ç–∫–µ –ø–∏—Ç–∞–Ω–Ω—è –≤—ñ–¥ AI —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é/—Ä–æ—Å—ñ–π—Å—å–∫–æ—é (—è–∫ –∑–≤–∏—á–Ω–æ).
    –Ø–∫—â–æ AI –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π –∞–±–æ –ø–æ–º–∏–ª–∫–∞ ‚Äî –ø–æ–≤–µ—Ä—Ç–∞—î –ª–æ–∫–∞–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç.
    """
    if not (AI_ENABLED and AI_AVAILABLE and ask_ai):
        return safe_ai_prompt()

    try:
        prompt = (
            "–¢–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç –∫–∞–º–µ—Ä–∏. –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –∑'—è–≤–∏–≤—Å—è –≤ –∫–∞–¥—Ä—ñ. "
            "–ó–∞–ø–∏—Ç–∞–π 1 –∫–æ—Ä–æ—Ç–∫–µ –ø–∏—Ç–∞–Ω–Ω—è (1 —Ä–µ—á–µ–Ω–Ω—è) —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é: "
            "—â–æ –≤—ñ–Ω —Ö–æ—á–µ –∑—Ä–æ–±–∏—Ç–∏ –∑–∞—Ä–∞–∑ / —è–∫—ñ –ø–ª–∞–Ω–∏."
        )
        msg = ask_ai(prompt).strip()
        return msg if msg else safe_ai_prompt()
    except Exception:
        return safe_ai_prompt()


def main():
    if not os.path.exists(MODEL_FILE):
        train_model()

    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read(MODEL_FILE)

    face_cascade = cv2.CascadeClassifier(
        cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
    )

    picam2 = Picamera2()
    config = picam2.create_preview_configuration(
        main={"size": (640, 480), "format": "XRGB8888"}
    )
    picam2.configure(config)
    picam2.start()
    time.sleep(1)

    confirmed_me = False
    me_streak = 0
    not_me_streak = 0

    last_text_ts = 0.0
    last_ai_ts = 0.0

    print("AI camera started (TEXT+AI)")
    if AI_ENABLED:
        print(f"AI: {'ON' if AI_AVAILABLE else 'OFF (ai_chat not found or error)'}")

    while True:
        try:
            frame = picam2.capture_array()
        except Exception:
            time.sleep(0.05)
            continue

        # Picamera2 (XRGB8888) -> –±–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ RGB
        frame_rgb = frame[:, :, :3]
        gray = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2GRAY)

        faces = face_cascade.detectMultiScale(gray, 1.2, 5, minSize=(80, 80))

        is_me_raw = False
        conf = None

        if len(faces) > 0:
            x, y, w, h = max(faces, key=lambda f: f[2] * f[3])
            face_roi = cv2.resize(gray[y:y+h, x:x+w], (200, 200))
            label, confidence = recognizer.predict(face_roi)
            conf = confidence
            if label == LABEL_ME and confidence < LBPH_THRESHOLD:
                is_me_raw = True

        # –°—Ç–∞–±—ñ–ª—ñ–∑–∞—Ü—ñ—è: streak
        if is_me_raw:
            me_streak += 1
            not_me_streak = 0
        else:
            not_me_streak += 1
            me_streak = 0

        prev = confirmed_me
        if (not confirmed_me) and me_streak >= ME_STREAK_ON:
            confirmed_me = True
        if confirmed_me and not_me_streak >= ME_STREAK_OFF:
            confirmed_me = False

        now = time.time()

        # –ü–æ–¥—ñ—è: –≤–ø—ñ–∑–Ω–∞–≤ (NOT YOU -> YOU)
        if confirmed_me and (not prev):
            if now - last_text_ts > TEXT_COOLDOWN_SEC:
                print("üë§ –¢–ï–ë–ï –í–ü–Ü–ó–ù–ê–ù–û | YOU ARE RECOGNIZED")
                last_text_ts = now

            # AI —ñ–Ω—ñ—Ü—ñ–∞—Ç–∏–≤–∞ (–∑ cooldown)
            if AI_ENABLED and (now - last_ai_ts) > AI_COOLDOWN_SEC:
                msg = get_proactive_ai_message()
                print("AI:", msg)
                last_ai_ts = now

        # –¢–µ–∫—Å—Ç –ø–æ–≤–µ—Ä—Ö –≤—ñ–¥–µ–æ
        if confirmed_me:
            cv2.putText(frame_rgb, "YOU", (20, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
            if conf is not None:
                cv2.putText(frame_rgb, f"conf:{conf:.1f}", (20, 80),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            cv2.putText(frame_rgb, "NOT YOU", (20, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)

        cv2.imshow("AI Assistant Cam (TEXT+AI)", frame_rgb)

        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break

        time.sleep(FRAME_SLEEP)

    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
